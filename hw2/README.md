# Домашнее задание №2: CUDA Matrix Multiplication

**Студент:** Макалодин Матвей  
**Курс:** Высокопроизводительные вычисления  
**Дата:** Декабрь 2024

---

## Обзор проекта

Данная домашняя работа включает реализацию умножения матриц на GPU с использованием CUDA. Проект состоит из 6 задач, каждая из которых демонстрирует различные техники оптимизации и подходы к программированию GPU.

## Структура проекта

```
hw2/
├── task1/          # Базовое умножение с глобальной памятью и pinned memory
├── task2a/         # Unified Memory версия
├── task2b/         # CUDA streams оптимизация
├── task2c/         # Shared Memory (блочное умножение)
├── task3/          # Оптимизация банков разделяемой памяти
├── task4/          # cuBLAS реализация
├── task5/          # OpenMP на GPU
├── task6/          # Профилирование с Nsight
└── README.md       # Этот файл
```

## Требования

- CUDA Toolkit (версия 11.0+)
- NVIDIA GPU с compute capability 7.5+
- Компилятор nvcc (через модуль nvhpc на кластере)
- Для Task 5: nvc компилятор (NVIDIA HPC SDK)
- Для Task 4: cuBLAS библиотека

## Установка и компиляция на кластере

### Загрузка модулей

```bash
module load nvidia_sdk/nvhpc/23.5
```

### Компиляция

Для каждой задачи:
```bash
cd task1  # или task2a, task2b, и т.д.
make
```

## Запуск на кластере

### Через SLURM (рекомендуется)

```bash
sbatch run_task1.sbatch
```

### Интерактивно

```bash
srun -n 1 --gpus=1 ./gemm [параметры]
```

### Выделение узла

```bash
salloc -n 1 --gpus=1
# После выделения можно запускать программу многократно
./gemm [параметры]
# Для освобождения узла: Ctrl+D
```

## Описание задач

### Task 1: Глобальная память (2 балла)

Реализация умножения матриц с использованием глобальной памяти GPU. Использование pinned memory для оптимизации передачи данных.

**Особенности:**
- Двумерная организация блоков и потоков
- Pinned memory для CPU ↔ GPU передачи
- Измерение времени через `cudaEventElapsedTime`

**Запуск:**
```bash
cd task1
make
./gemm [N]
```

### Task 2a: Unified Memory (1 балл)

Версия с использованием Unified Memory - единого адресного пространства для CPU и GPU без явного копирования.

**Особенности:**
- `cudaMallocManaged` для выделения памяти
- Автоматическое управление памятью
- Упрощение кода

### Task 2b: CUDA Streams (2 балла)

Оптимизация через асинхронное копирование и параллельное выполнение с использованием CUDA streams.

**Особенности:**
- Разделение матриц на тайлы
- Множественные streams для параллельной обработки
- Перекрытие вычислений и передачи данных

**Запуск:**
```bash
cd task2b
./gemm [N] [numStreams] [tileSize]
```

### Task 2c: Shared Memory (1 балл)

Блочное умножение матриц с использованием разделяемой памяти для уменьшения обращений к глобальной памяти.

**Особенности:**
- Использование `__shared__` памяти
- Блочный алгоритм
- Синхронизация через `__syncthreads()`

### Task 3: Оптимизация банков памяти (1 балл) *

Исследование влияния bank conflicts на производительность и их устранение через padding.

**Особенности:**
- Сравнение версий с padding и без
- Анализ зависимости времени от оптимизаций

### Task 4: cuBLAS (1 балл)

Использование высокооптимизированной библиотеки cuBLAS для умножения матриц.

**Особенности:**
- Функция `cublasDgemm`
- Максимальная производительность
- Простота использования

### Task 5: OpenMP на GPU (1 балл)

Реализация с использованием OpenMP target directives для программирования GPU.

**Особенности:**
- Компиляция через `nvc -mp=gpu`
- OpenMP синтаксис для GPU
- Портативность кода

**Компиляция:**
```bash
cd task5
nvc -mp=gpu -O3 -o gemm gemm.c
```

### Task 6: Профилирование Nsight (1 балл) *

Документация и примеры использования NVIDIA Nsight Systems для профилирования.

**См. task6/README.md для подробностей**

## Анализ результатов

Для каждой задачи программа выводит:
- Время выполнения (мс)
- Производительность (GFLOPS)
- Результаты верификации
- **Автоматическое сохранение результатов в CSV файлы**

### Построение графиков

После запуска всех задач создайте графики анализа:

```bash
# Установить Python зависимости
pip install -r requirements.txt

# Запустить анализ
python analyze_results.py
```

Скрипт создаст следующие графики:
- **performance_comparison.png** - сравнение всех методов по размеру матрицы
- **scalability_analysis.png** - анализ масштабируемости
- **streams_analysis.png** - анализ зависимости от количества streams (Task 2b)
- **bank_conflicts_analysis.png** - сравнение версий с padding и без (Task 3)

### Создание PDF

Для создания PDF файла из графиков:

```bash
# Используя ImageMagick
./create_pdf.sh

# Или вручную
convert *.png gemm.pdf
```

Графики должны содержать:
- Подписи осей (названия и единицы измерения)
- Легенду
- Названия графиков
- Читаемый размер шрифта

## Файлы для сдачи

Перед сдачей необходимо отправить на почту etararushkin@hse.ru:

1. **gemm.cu** - основной код программы (для каждой задачи)
2. **gemm.pdf** - файл с графиками анализа масштабируемости
   - Должны быть подписи осей, легенда и названия
   - График должен быть читаемым
3. **README.txt** - описание процесса компиляции и запуска на узлах Харизмы

## Примечания

- Задания 3 и 6 являются исследовательскими (помечены *)
- За основную часть можно получить максимум 8 баллов
- Рекомендуется сдавать задания последовательно

## Полезные команды

```bash
# Проверка доступности GPU
nvidia-smi

# Информация о CUDA
nvcc --version

# Компиляция CUDA
nvcc -O3 -arch=sm_75 -o gemm gemm.cu

# Компиляция OpenMP GPU
nvc -mp=gpu -O3 -o gemm gemm.c

# Профилирование
nsys profile --output=profile ./gemm
```

## Контакты

При возникновении вопросов обращайтесь к преподавателю.

