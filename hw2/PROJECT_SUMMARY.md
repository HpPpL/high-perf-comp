# Сводка проекта: CUDA Matrix Multiplication

## Выполненные задачи

### ✅ Task 1: Глобальная память (2 балла)
- Реализовано умножение матриц с использованием глобальной памяти
- Использование pinned memory для оптимизации передачи
- Двумерная организация блоков и потоков (16x16)
- Измерение времени через `cudaEventElapsedTime`

### ✅ Task 2a: Unified Memory (1 балл)
- Реализация с `cudaMallocManaged`
- Автоматическое управление памятью
- Нет явного копирования данных

### ✅ Task 2b: CUDA Streams (2 балла)
- Использование множественных streams
- Демонстрация параллельного выполнения kernels
- Параметры: количество streams, размер матрицы

### ✅ Task 2c: Shared Memory (1 балл)
- Блочное умножение матриц
- Использование `__shared__` памяти
- Синхронизация через `__syncthreads()`
- Размер тайла: 16x16

### ✅ Task 3: Оптимизация банков памяти (1 балл) *
- Сравнение версий с padding и без
- Анализ влияния bank conflicts
- Метрики производительности

### ✅ Task 4: cuBLAS (1 балл)
- Использование `cublasDgemm`
- Высокооптимизированная библиотека
- Максимальная производительность

### ✅ Task 5: OpenMP на GPU (1 балл)
- Реализация с OpenMP target directives
- Компиляция через `nvc -mp=gpu`
- Портативный код

### ✅ Task 6: Профилирование Nsight (1 балл) *
- Документация по использованию Nsight Systems
- Примеры команд профилирования
- Скрипт для автоматического профилирования

## Структура файлов

Каждая задача содержит:
- `src/gemm.cu` (или `gemm.c` для task5) - исходный код
- `Makefile` - система сборки
- `README.md` - документация задачи
- `run_task*.sbatch` - SLURM скрипт для запуска на кластере

## Компиляция и запуск

### На кластере:
```bash
module load nvidia_sdk/nvhpc/23.5
cd task1  # или другая задача
make
sbatch run_task1.sbatch
```

### Интерактивно:
```bash
srun -n 1 --gpus=1 ./gemm [параметры]
```

## Особенности реализации

1. **Column-major порядок** - все матрицы хранятся в column-major
2. **Верификация результатов** - сравнение с CPU версией
3. **Измерение производительности** - время и GFLOPS
4. **Обработка ошибок** - проверка доступности GPU
5. **Документация** - подробные README для каждой задачи

## Следующие шаги

1. Запустить все задачи на кластере
2. Собрать результаты измерений
3. Создать графики зависимости времени и производительности от параметров
4. Подготовить gemm.pdf с графиками
5. Отправить файлы на проверку

## Примечания

- Все задачи компилируются без ошибок
- Код следует best practices CUDA
- Документация на русском языке
- Готово к запуску на кластере Харизма

