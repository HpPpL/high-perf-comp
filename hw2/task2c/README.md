# Task 2c: Shared Memory (Tiled Matrix Multiplication)

## Описание

Реализация блочного умножения матриц с использованием разделяемой памяти (Shared Memory). Это одна из ключевых оптимизаций для CUDA.

## Особенности

- Использование `__shared__` памяти для хранения тайлов матриц
- Блочный алгоритм умножения матриц
- Уменьшение обращений к глобальной памяти
- Синхронизация потоков через `__syncthreads()`

## Принцип работы

1. Матрицы разбиваются на тайлы размером 16x16
2. Каждый блок потоков загружает соответствующие тайлы в shared memory
3. Потоки блока совместно вычисляют частичное произведение
4. Результат записывается в глобальную память

## Преимущества

- **Меньше обращений к глобальной памяти**: данные переиспользуются из shared memory
- **Высокая пропускная способность**: shared memory быстрее глобальной памяти
- **Лучшая утилизация кэша**: данные остаются в shared memory между итерациями

## Компиляция и запуск

```bash
module load nvidia_sdk/nvhpc/23.5
make
./gemm [N]
```

## Ограничения

- Размер тайла ограничен размером shared memory (обычно 48KB на блок)
- Требуется синхронизация между загрузкой и вычислениями
- Размер блока должен быть кратен размеру тайла

